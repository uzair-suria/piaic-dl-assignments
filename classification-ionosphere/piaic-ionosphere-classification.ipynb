{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Ionosphere Data Problem\n",
    "\n",
    "Classification of radar returns from the ionosphere\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description\n",
    "\n",
    "This radar data was collected by a system in Goose Bay, Labrador. This system consists of a phased array of 16 high-frequency antennas with a total transmitted power on the order of 6.4 kilowatts. See the paper for more details. The targets were free electrons in the ionosphere. \"Good\" radar returns are those showing evidence of some type of structure in the ionosphere. \"Bad\" returns are those that do not; their signals pass through the ionosphere.\n",
    "\n",
    "Received signals were processed using an autocorrelation function whose arguments are the time of a pulse and the pulse number. There were 17 pulse numbers for the Goose Bay system. Instances in this databse are described by 2 attributes per pulse number, corresponding to the complex values returned by the function resulting from the complex electromagnetic signal.\n",
    "\n",
    "[Download Dataset](https://raw.githubusercontent.com/ramsha275/ML_Datasets/main/ionosphere_data.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute Information\n",
    "\n",
    "- All 34 are continuous\n",
    "- The 35th attribute is either \"good\" or \"bad\" according to the definition summarized above. This is a binary classification task.\n",
    "\n",
    " <br><br>\n",
    "\n",
    "<table border=\"1\"  cellpadding=\"6\">\n",
    "\t<tbody>\n",
    "        <tr>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Data Set Characteristics:&nbsp;&nbsp;</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Multivariate</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Instances:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">351</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Area:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Physical</p></td>\n",
    "        </tr>\n",
    "     </tbody>\n",
    "    </table>\n",
    "<table border=\"1\" cellpadding=\"6\">\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Attribute Characteristics:</b></p></td>\n",
    "            <td><p class=\"normal\">Integer,Real</p></td>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Attributes:</b></p></td>\n",
    "            <td><p class=\"normal\">34</p></td>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Date Donated</b></p></td>\n",
    "            <td><p class=\"normal\">N/A</p></td>\n",
    "        </tr>\n",
    "     </tbody>\n",
    "    </table>\n",
    "<table border=\"1\" cellpadding=\"6\">\t\n",
    "    <tbody>\n",
    "    <tr>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Associated Tasks:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Classification</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Missing Values?</b></p></td>\n",
    "\t\t<td><p class=\"normal\">N/A</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Web Hits:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">N/A</p></td>\n",
    "\t</tr>\n",
    "    </tbody>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WORKFLOW :\n",
    "- Load Data\n",
    "- Check Missing Values ( If Exist ; Fill each record with mean of its feature ) or any usless column.\n",
    "- Shuffle the data if needed.\n",
    "- Standardized the Input Variables. **Hint**: Centeralized the data\n",
    "- Split into 60 and 40 ratio.\n",
    "- Encode labels.\n",
    "- Model : 1 hidden layers including 16 unit.\n",
    "- Compilation Step (Note : Its a Binary problem , select loss , metrics according to it)\n",
    "- Train the Model with Epochs (100).\n",
    "- If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .\n",
    "- Prediction should be > **92%**\n",
    "- Evaluation Step\n",
    "- Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "from tensorflow.keras import models, layers, activations, metrics, regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/ionosphere_piaic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0         1         0   0.99539  -0.05889   0.85243   0.02306   0.83398   \n",
       "1         1         0   1.00000  -0.18829   0.93035  -0.36156  -0.10868   \n",
       "2         1         0   1.00000  -0.03365   1.00000   0.00485   1.00000   \n",
       "3         1         0   1.00000  -0.45161   1.00000   1.00000   0.71216   \n",
       "4         1         0   1.00000  -0.02401   0.94140   0.06531   0.92106   \n",
       "\n",
       "   feature8  feature9  feature10  ...  feature26  feature27  feature28  \\\n",
       "0  -0.37708   1.00000    0.03760  ...   -0.51171    0.41078   -0.46168   \n",
       "1  -0.93597   1.00000   -0.04549  ...   -0.26569   -0.20468   -0.18401   \n",
       "2  -0.12062   0.88965    0.01198  ...   -0.40220    0.58984   -0.22145   \n",
       "3  -1.00000   0.00000    0.00000  ...    0.90695    0.51613    1.00000   \n",
       "4  -0.23255   0.77152   -0.16399  ...   -0.65158    0.13290   -0.53206   \n",
       "\n",
       "   feature29  feature30  feature31  feature32  feature33  feature34  label  \n",
       "0    0.21266   -0.34090    0.42267   -0.54487    0.18641   -0.45300      g  \n",
       "1   -0.19040   -0.11593   -0.16626   -0.06288   -0.13738   -0.02447      b  \n",
       "2    0.43100   -0.17365    0.60436   -0.24180    0.56045   -0.38238      g  \n",
       "3    1.00000   -0.20099    0.25682    1.00000   -0.32382    1.00000      b  \n",
       "4    0.02431   -0.62197   -0.05707   -0.59573   -0.04608   -0.65697      g  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Missing Data or Useless Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_non_unique (df):\n",
    "    non_unique = []\n",
    "    cols = df.columns.values\n",
    "    for col in cols:\n",
    "        if (len(df[col].unique())) == 1:\n",
    "            non_unique.append(col)\n",
    "        else:\n",
    "            pass\n",
    "    return non_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature2']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_non_unique(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature1     0\n",
       "feature2     0\n",
       "feature3     0\n",
       "feature4     0\n",
       "feature5     0\n",
       "feature6     0\n",
       "feature7     0\n",
       "feature8     0\n",
       "feature9     0\n",
       "feature10    0\n",
       "feature11    0\n",
       "feature12    0\n",
       "feature13    0\n",
       "feature14    0\n",
       "feature15    0\n",
       "feature16    0\n",
       "feature17    0\n",
       "feature18    0\n",
       "feature19    0\n",
       "feature20    0\n",
       "feature21    0\n",
       "feature22    0\n",
       "feature23    0\n",
       "feature24    0\n",
       "feature25    0\n",
       "feature26    0\n",
       "feature27    0\n",
       "feature28    0\n",
       "feature29    0\n",
       "feature30    0\n",
       "feature31    0\n",
       "feature32    0\n",
       "feature33    0\n",
       "feature34    0\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `feature2` is useless since the value in this column does not change.\n",
    "* There is no missing data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Data\n",
    "\n",
    "Shuffling of data not required since the splitting will be done using scikit-learn `train_test_split`, which shuffles the data autumatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((351, 33), (351,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['feature2', 'label'], axis=1).copy(deep=True)\n",
    "y = df.label.copy(deep=True)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 33)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(210,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(141, 33)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(141,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "\n",
    "display(X_train.shape, y_train.shape)\n",
    "display(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>...</th>\n",
       "      <th>feature25</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.627634</td>\n",
       "      <td>0.070545</td>\n",
       "      <td>0.605517</td>\n",
       "      <td>0.092352</td>\n",
       "      <td>0.567430</td>\n",
       "      <td>0.060537</td>\n",
       "      <td>0.513531</td>\n",
       "      <td>0.197840</td>\n",
       "      <td>0.501930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399884</td>\n",
       "      <td>-0.080945</td>\n",
       "      <td>0.578475</td>\n",
       "      <td>-0.064104</td>\n",
       "      <td>0.409104</td>\n",
       "      <td>-0.001468</td>\n",
       "      <td>0.369162</td>\n",
       "      <td>-0.003524</td>\n",
       "      <td>0.356149</td>\n",
       "      <td>-0.001488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.340747</td>\n",
       "      <td>0.532300</td>\n",
       "      <td>0.452647</td>\n",
       "      <td>0.517727</td>\n",
       "      <td>0.462462</td>\n",
       "      <td>0.488570</td>\n",
       "      <td>0.538218</td>\n",
       "      <td>0.528546</td>\n",
       "      <td>0.483928</td>\n",
       "      <td>0.561851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.582991</td>\n",
       "      <td>0.515960</td>\n",
       "      <td>0.495687</td>\n",
       "      <td>0.564562</td>\n",
       "      <td>0.554912</td>\n",
       "      <td>0.505084</td>\n",
       "      <td>0.586191</td>\n",
       "      <td>0.537560</td>\n",
       "      <td>0.508693</td>\n",
       "      <td>0.464099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.473447</td>\n",
       "      <td>-0.030840</td>\n",
       "      <td>0.424420</td>\n",
       "      <td>-0.040325</td>\n",
       "      <td>0.224290</td>\n",
       "      <td>-0.076485</td>\n",
       "      <td>0.065855</td>\n",
       "      <td>-0.045055</td>\n",
       "      <td>0.029903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.344618</td>\n",
       "      <td>0.334335</td>\n",
       "      <td>-0.426683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.211477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.239347</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.196345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.880940</td>\n",
       "      <td>0.025385</td>\n",
       "      <td>0.814235</td>\n",
       "      <td>0.012875</td>\n",
       "      <td>0.770875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.702940</td>\n",
       "      <td>0.011940</td>\n",
       "      <td>0.696490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560525</td>\n",
       "      <td>-0.007625</td>\n",
       "      <td>0.739150</td>\n",
       "      <td>-0.017205</td>\n",
       "      <td>0.526815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.535130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405165</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.224825</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.274312</td>\n",
       "      <td>0.988393</td>\n",
       "      <td>0.315090</td>\n",
       "      <td>0.977175</td>\n",
       "      <td>0.624575</td>\n",
       "      <td>0.988650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.911095</td>\n",
       "      <td>0.147347</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.154862</td>\n",
       "      <td>0.917887</td>\n",
       "      <td>0.159278</td>\n",
       "      <td>0.865988</td>\n",
       "      <td>0.203130</td>\n",
       "      <td>0.798382</td>\n",
       "      <td>0.127602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature1    feature3    feature4    feature5    feature6    feature7  \\\n",
       "count  210.000000  210.000000  210.000000  210.000000  210.000000  210.000000   \n",
       "mean     0.866667    0.627634    0.070545    0.605517    0.092352    0.567430   \n",
       "std      0.340747    0.532300    0.452647    0.517727    0.462462    0.488570   \n",
       "min      0.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%      1.000000    0.473447   -0.030840    0.424420   -0.040325    0.224290   \n",
       "50%      1.000000    0.880940    0.025385    0.814235    0.012875    0.770875   \n",
       "75%      1.000000    1.000000    0.224825    1.000000    0.274312    0.988393   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         feature8    feature9   feature10   feature11  ...   feature25  \\\n",
       "count  210.000000  210.000000  210.000000  210.000000  ...  210.000000   \n",
       "mean     0.060537    0.513531    0.197840    0.501930  ...    0.399884   \n",
       "std      0.538218    0.528546    0.483928    0.561851  ...    0.582991   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000  ...   -1.000000   \n",
       "25%     -0.076485    0.065855   -0.045055    0.029903  ...    0.000000   \n",
       "50%      0.000000    0.702940    0.011940    0.696490  ...    0.560525   \n",
       "75%      0.315090    0.977175    0.624575    0.988650  ...    0.911095   \n",
       "max      1.000000    1.000000    1.000000    1.000000  ...    1.000000   \n",
       "\n",
       "        feature26   feature27   feature28   feature29   feature30   feature31  \\\n",
       "count  210.000000  210.000000  210.000000  210.000000  210.000000  210.000000   \n",
       "mean    -0.080945    0.578475   -0.064104    0.409104   -0.001468    0.369162   \n",
       "std      0.515960    0.495687    0.564562    0.554912    0.505084    0.586191   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%     -0.344618    0.334335   -0.426683    0.000000   -0.211477    0.000000   \n",
       "50%     -0.007625    0.739150   -0.017205    0.526815    0.000000    0.535130   \n",
       "75%      0.147347    1.000000    0.154862    0.917887    0.159278    0.865988   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "        feature32   feature33   feature34  \n",
       "count  210.000000  210.000000  210.000000  \n",
       "mean    -0.003524    0.356149   -0.001488  \n",
       "std      0.537560    0.508693    0.464099  \n",
       "min     -1.000000   -1.000000   -1.000000  \n",
       "25%     -0.239347    0.000000   -0.196345  \n",
       "50%      0.000000    0.405165    0.000000  \n",
       "75%      0.203130    0.798382    0.127602  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = [\n",
    "    ('Standard Scaling', StandardScaler(), X.columns.values)\n",
    "]\n",
    "\n",
    "column_transformer = ColumnTransformer(transformers=transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 33)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_n = column_transformer.fit_transform(X_train)\n",
    "X_train_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141, 33)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_n = column_transformer.transform(X_test)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['b', 'g'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4      g\n",
       "317    g\n",
       "113    g\n",
       "157    g\n",
       "318    g\n",
       "      ..\n",
       "248    b\n",
       "214    b\n",
       "124    b\n",
       "141    g\n",
       "179    g\n",
       "Name: label, Length: 210, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(16, activation=activations.relu, kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(layers.Dense(1, activation=activations.sigmoid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=[metrics.AUC()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.8821 - auc_2: 0.4066 - val_loss: 0.7127 - val_auc_2: 0.6082\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7938 - auc_2: 0.4852 - val_loss: 0.6588 - val_auc_2: 0.6859\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.7424 - auc_2: 0.5441 - val_loss: 0.6171 - val_auc_2: 0.7376\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.7012 - auc_2: 0.5952 - val_loss: 0.5889 - val_auc_2: 0.7729\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6704 - auc_2: 0.6356 - val_loss: 0.5585 - val_auc_2: 0.8024\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6402 - auc_2: 0.6776 - val_loss: 0.5335 - val_auc_2: 0.8188\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6127 - auc_2: 0.7168 - val_loss: 0.5081 - val_auc_2: 0.8318\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5878 - auc_2: 0.7447 - val_loss: 0.4858 - val_auc_2: 0.8412\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5645 - auc_2: 0.7738 - val_loss: 0.4650 - val_auc_2: 0.8800\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5433 - auc_2: 0.7925 - val_loss: 0.4454 - val_auc_2: 0.9024\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5241 - auc_2: 0.8106 - val_loss: 0.4275 - val_auc_2: 0.9176\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5073 - auc_2: 0.8227 - val_loss: 0.4103 - val_auc_2: 0.9235\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4899 - auc_2: 0.8377 - val_loss: 0.3947 - val_auc_2: 0.9306\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4742 - auc_2: 0.8510 - val_loss: 0.3810 - val_auc_2: 0.9365\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4602 - auc_2: 0.8625 - val_loss: 0.3686 - val_auc_2: 0.9506\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4466 - auc_2: 0.8731 - val_loss: 0.3566 - val_auc_2: 0.9529\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4347 - auc_2: 0.8820 - val_loss: 0.3474 - val_auc_2: 0.9553\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4233 - auc_2: 0.8923 - val_loss: 0.3368 - val_auc_2: 0.9624\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4120 - auc_2: 0.9009 - val_loss: 0.3257 - val_auc_2: 0.9647\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4010 - auc_2: 0.9076 - val_loss: 0.3170 - val_auc_2: 0.9682\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.3908 - auc_2: 0.9132 - val_loss: 0.3067 - val_auc_2: 0.9729\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.3793 - auc_2: 0.9216 - val_loss: 0.2980 - val_auc_2: 0.9765\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.3707 - auc_2: 0.9265 - val_loss: 0.2898 - val_auc_2: 0.9765\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.3610 - auc_2: 0.9328 - val_loss: 0.2820 - val_auc_2: 0.9788\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.3516 - auc_2: 0.9386 - val_loss: 0.2753 - val_auc_2: 0.9788\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.3430 - auc_2: 0.9436 - val_loss: 0.2682 - val_auc_2: 0.9812\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.3346 - auc_2: 0.9464 - val_loss: 0.2619 - val_auc_2: 0.9835\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.3258 - auc_2: 0.9508 - val_loss: 0.2555 - val_auc_2: 0.9859\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3175 - auc_2: 0.9548 - val_loss: 0.2491 - val_auc_2: 0.9859\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.3099 - auc_2: 0.9572 - val_loss: 0.2445 - val_auc_2: 0.9859\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.3021 - auc_2: 0.9610 - val_loss: 0.2384 - val_auc_2: 0.9859\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.2956 - auc_2: 0.9630 - val_loss: 0.2349 - val_auc_2: 0.9859\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2883 - auc_2: 0.9666 - val_loss: 0.2304 - val_auc_2: 0.9859\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2824 - auc_2: 0.9683 - val_loss: 0.2259 - val_auc_2: 0.9859\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.2769 - auc_2: 0.9692 - val_loss: 0.2211 - val_auc_2: 0.9871\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.2700 - auc_2: 0.9712 - val_loss: 0.2172 - val_auc_2: 0.9882\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2636 - auc_2: 0.9729 - val_loss: 0.2132 - val_auc_2: 0.9882\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2582 - auc_2: 0.9731 - val_loss: 0.2091 - val_auc_2: 0.9882\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2523 - auc_2: 0.9743 - val_loss: 0.2050 - val_auc_2: 0.9882\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.2461 - auc_2: 0.9762 - val_loss: 0.2020 - val_auc_2: 0.9882\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.2414 - auc_2: 0.9769 - val_loss: 0.1993 - val_auc_2: 0.9882\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.2361 - auc_2: 0.9779 - val_loss: 0.1958 - val_auc_2: 0.9882\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2310 - auc_2: 0.9792 - val_loss: 0.1933 - val_auc_2: 0.9882\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2263 - auc_2: 0.9801 - val_loss: 0.1919 - val_auc_2: 0.9882\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2217 - auc_2: 0.9808 - val_loss: 0.1887 - val_auc_2: 0.9882\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.2174 - auc_2: 0.9821 - val_loss: 0.1867 - val_auc_2: 0.9894\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2128 - auc_2: 0.9821 - val_loss: 0.1848 - val_auc_2: 0.9894\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2085 - auc_2: 0.9832 - val_loss: 0.1823 - val_auc_2: 0.9906\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2044 - auc_2: 0.9848 - val_loss: 0.1810 - val_auc_2: 0.9906\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2005 - auc_2: 0.9856 - val_loss: 0.1796 - val_auc_2: 0.9906\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1972 - auc_2: 0.9855 - val_loss: 0.1767 - val_auc_2: 0.9906\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1935 - auc_2: 0.9863 - val_loss: 0.1753 - val_auc_2: 0.9906\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1901 - auc_2: 0.9861 - val_loss: 0.1742 - val_auc_2: 0.9906\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1865 - auc_2: 0.9872 - val_loss: 0.1739 - val_auc_2: 0.9906\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1832 - auc_2: 0.9876 - val_loss: 0.1722 - val_auc_2: 0.9906\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1797 - auc_2: 0.9883 - val_loss: 0.1708 - val_auc_2: 0.9906\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1767 - auc_2: 0.9888 - val_loss: 0.1701 - val_auc_2: 0.9906\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1727 - auc_2: 0.9902 - val_loss: 0.1692 - val_auc_2: 0.9929\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1700 - auc_2: 0.9900 - val_loss: 0.1693 - val_auc_2: 0.9941\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1674 - auc_2: 0.9911 - val_loss: 0.1679 - val_auc_2: 0.9929\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1646 - auc_2: 0.9907 - val_loss: 0.1660 - val_auc_2: 0.9929\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1622 - auc_2: 0.9918 - val_loss: 0.1660 - val_auc_2: 0.9929\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1592 - auc_2: 0.9919 - val_loss: 0.1639 - val_auc_2: 0.9929\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1566 - auc_2: 0.9922 - val_loss: 0.1633 - val_auc_2: 0.9929\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1544 - auc_2: 0.9925 - val_loss: 0.1629 - val_auc_2: 0.9929\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1515 - auc_2: 0.9929 - val_loss: 0.1630 - val_auc_2: 0.9929\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1491 - auc_2: 0.9930 - val_loss: 0.1623 - val_auc_2: 0.9929\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1471 - auc_2: 0.9932 - val_loss: 0.1613 - val_auc_2: 0.9929\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1444 - auc_2: 0.9937 - val_loss: 0.1607 - val_auc_2: 0.9929\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1423 - auc_2: 0.9939 - val_loss: 0.1609 - val_auc_2: 0.9929\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1405 - auc_2: 0.9939 - val_loss: 0.1604 - val_auc_2: 0.9929\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1380 - auc_2: 0.9949 - val_loss: 0.1594 - val_auc_2: 0.9929\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1360 - auc_2: 0.9951 - val_loss: 0.1590 - val_auc_2: 0.9929\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1339 - auc_2: 0.9955 - val_loss: 0.1599 - val_auc_2: 0.9929\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1317 - auc_2: 0.9960 - val_loss: 0.1593 - val_auc_2: 0.9929\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1296 - auc_2: 0.9962 - val_loss: 0.1579 - val_auc_2: 0.9941\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1273 - auc_2: 0.9963 - val_loss: 0.1576 - val_auc_2: 0.9929\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1254 - auc_2: 0.9967 - val_loss: 0.1571 - val_auc_2: 0.9929\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1235 - auc_2: 0.9970 - val_loss: 0.1578 - val_auc_2: 0.9929\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1216 - auc_2: 0.9974 - val_loss: 0.1580 - val_auc_2: 0.9929\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1193 - auc_2: 0.9975 - val_loss: 0.1588 - val_auc_2: 0.9953\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1181 - auc_2: 0.9976 - val_loss: 0.1584 - val_auc_2: 0.9953\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1157 - auc_2: 0.9977 - val_loss: 0.1588 - val_auc_2: 0.9953\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1139 - auc_2: 0.9981 - val_loss: 0.1590 - val_auc_2: 0.9953\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1119 - auc_2: 0.9982 - val_loss: 0.1591 - val_auc_2: 0.9953\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1103 - auc_2: 0.9984 - val_loss: 0.1590 - val_auc_2: 0.9953\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1086 - auc_2: 0.9984 - val_loss: 0.1582 - val_auc_2: 0.9941\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1069 - auc_2: 0.9988 - val_loss: 0.1584 - val_auc_2: 0.9929\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1056 - auc_2: 0.9987 - val_loss: 0.1606 - val_auc_2: 0.9929\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1039 - auc_2: 0.9989 - val_loss: 0.1596 - val_auc_2: 0.9941\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1017 - auc_2: 0.9994 - val_loss: 0.1568 - val_auc_2: 0.9941\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1008 - auc_2: 0.9994 - val_loss: 0.1582 - val_auc_2: 0.9941\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0992 - auc_2: 0.9994 - val_loss: 0.1580 - val_auc_2: 0.9941\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0977 - auc_2: 0.9994 - val_loss: 0.1582 - val_auc_2: 0.9941\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0967 - auc_2: 0.9994 - val_loss: 0.1588 - val_auc_2: 0.9941\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0954 - auc_2: 0.9994 - val_loss: 0.1607 - val_auc_2: 0.9929\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0942 - auc_2: 0.9994 - val_loss: 0.1602 - val_auc_2: 0.9941\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0924 - auc_2: 0.9994 - val_loss: 0.1607 - val_auc_2: 0.9929\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0911 - auc_2: 0.9994 - val_loss: 0.1609 - val_auc_2: 0.9941\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0900 - auc_2: 0.9994 - val_loss: 0.1600 - val_auc_2: 0.9941\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_n, y_train_encoded, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 0s/step - loss: 0.3831 - auc_2: 0.9402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3830978572368622, 0.9402198195457458]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_n, y_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds = model.predict(X_test_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.around(y_test_preds, decimals=0).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PIAIC",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
